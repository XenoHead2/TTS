{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Authentication Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df1767a3d1cc"
      },
      "source": [
        "The Gemini API uses API keys for authentication. This notebook walks you through creating an API key, and using it with the Python SDK or a command-line tool like `curl`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhFKmRmxi5B-"
      },
      "source": [
        "## Create an API key\n",
        "\n",
        "You can [create](https://aistudio.google.com/app/apikey) your API key using Google AI Studio with a single click.  \n",
        "\n",
        "Remember to treat your API key like a password. Don't accidentally save it in a notebook or source file you later commit to GitHub. This notebook shows you two ways you can securely store your API key.\n",
        "\n",
        "* If you're using Google Colab, it's recommended to store your key in Colab Secrets.\n",
        "\n",
        "* If you're using a different development environment (or calling the Gemini API through `cURL` in your terminal), it's recommended to store your key in an [environment variable](https://en.wikipedia.org/wiki/Environment_variable).\n",
        "\n",
        "Let's start with Colab Secrets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEoigYI9Jw_K"
      },
      "source": [
        "## Add your key to Colab Secrets\n",
        "\n",
        "Add your API key to the Colab Secrets manager to securely store it.\n",
        "\n",
        "1. Open your Google Colab notebook and click on the ðŸ”‘ **Secrets** tab in the left panel.\n",
        "   \n",
        "   <img src=\"https://storage.googleapis.com/generativeai-downloads/images/secrets.jpg\" alt=\"You can find the Secrets tab on the left panel.\" width=50%>\n",
        "\n",
        "2. Create a new secret with the name `GOOGLE_API_KEY`.\n",
        "3. Copy and paste your API key into the `Value` input box of `GOOGLE_API_KEY`.\n",
        "4. Toggle the button on the left to allow all notebooks access to the secret.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRY1eioF4gUB"
      },
      "source": [
        "## Install the Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xuiLSV7amy3P"
      },
      "outputs": [],
      "source": [
        "%pip install -qU 'google-genai>=1.0.0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dw8ygh74mVc"
      },
      "source": [
        "## Configure the SDK with your API key\n",
        "\n",
        "You create a client using your API key, but instead of pasting your key into the notebook, you'll read it from Colab Secrets thanks to `userdata`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DTl-qZp34sht"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7ceb7517bf5"
      },
      "source": [
        "Now choose a model. The Gemini API offers different models that are optimized for specific use cases. For more information check [Gemini models](https://ai.google.dev/gemini-api/docs/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7135d9ae3e4b"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite-preview-06-17\",\"gemini-2.0-flash\",\"gemini-2.5-flash\",\"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr7oAO6-nMsE"
      },
      "source": [
        "And that's it! Now you're ready to call the Gemini API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "n6sXnWrJoKoo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d34d2934-66b0-4743-90d5-00b2edc0c322"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Python provides extremely powerful and efficient built-in ways to sort lists, so you rarely need to implement sorting algorithms yourself.\n\nHere are the two primary methods, along with explanations and examples:\n\n---\n\n## 1. `list.sort()` Method (Sorts In-Place)\n\nThis method sorts the list **in-place**, meaning it modifies the original list directly and doesn't return a new list. It returns `None`.\n\n**When to use:** When you no longer need the original unsorted list and want to save memory by not creating a new one.\n\n```python\n# --- Example 1: Basic numeric sort ---\nmy_list = [3, 1, 4, 1, 5, 9, 2, 6]\nprint(\"Original list:\", my_list)\n\nmy_list.sort() # Sorts the list in-place\nprint(\"Sorted list (in-place):\", my_list)\n\n# --- Example 2: Sorting strings alphabetically ---\nwords = [\"banana\", \"apple\", \"cherry\", \"date\"]\nprint(\"\\nOriginal words:\", words)\nwords.sort()\nprint(\"Sorted words (in-place):\", words)\n\n# --- Example 3: Sorting in descending order ---\nnumbers = [10, 5, 8, 2, 12]\nprint(\"\\nOriginal numbers:\", numbers)\nnumbers.sort(reverse=True) # Use reverse=True for descending order\nprint(\"Sorted numbers (descending):\", numbers)\n\n# --- Example 4: Sorting with a custom key (by length of strings) ---\ncolors = [\"red\", \"blue\", \"green\", \"yellow\", \"purple\"]\nprint(\"\\nOriginal colors:\", colors)\ncolors.sort(key=len) # Sorts by the length of each string\nprint(\"Sorted colors (by length):\", colors)\n\n# --- Example 5: Sorting a list of tuples by a specific element (e.g., age) ---\npeople = [(\"Alice\", 30), (\"Bob\", 25), (\"Charlie\", 35)]\nprint(\"\\nOriginal people data:\", people)\npeople.sort(key=lambda person: person[1]) # Sorts by the second element (age)\nprint(\"Sorted people (by age):\", people)\n```\n\n**Key Points about `list.sort()`:**\n*   **Modifies original:** `my_list` itself is changed.\n*   **Returns `None`:** Don't do `new_list = my_list.sort()`, as `new_list` will be `None`.\n\n---\n\n## 2. `sorted()` Function (Returns a New Sorted List)\n\nThis built-in function takes an iterable (like a list, tuple, string, set, etc.) and returns a **new sorted list**. The original iterable remains unchanged.\n\n**When to use:** When you need to preserve the original unsorted list or when you want to sort something that isn't a list (like a tuple or set).\n\n```python\n# --- Example 1: Basic numeric sort ---\nmy_list = [3, 1, 4, 1, 5, 9, 2, 6]\nprint(\"Original list:\", my_list)\n\nnew_sorted_list = sorted(my_list) # Returns a new sorted list\nprint(\"New sorted list:\", new_sorted_list)\nprint(\"Original list (unchanged):\", my_list) # Original list is still the same\n\n# --- Example 2: Sorting a tuple (sorted() works on any iterable) ---\nmy_tuple = (5, 2, 8, 1, 9)\nprint(\"\\nOriginal tuple:\", my_tuple)\nnew_sorted_list_from_tuple = sorted(my_tuple)\nprint(\"New sorted list from tuple:\", new_sorted_list_from_tuple)\nprint(\"Original tuple (unchanged):\", my_tuple)\n\n# --- Example 3: Sorting in descending order ---\ndata = [10, 5, 8, 2, 12]\nprint(\"\\nOriginal data:\", data)\ndescending_data = sorted(data, reverse=True)\nprint(\"New sorted data (descending):\", descending_data)\n\n# --- Example 4: Sorting with a custom key (case-insensitive string sort) ---\nnames = [\"Alice\", \"bob\", \"Charlie\", \"david\"]\nprint(\"\\nOriginal names:\", names)\ncase_insensitive_names = sorted(names, key=str.lower) # Sorts by lowercase version of names\nprint(\"Sorted names (case-insensitive):\", case_insensitive_names)\n\n# --- Example 5: Sorting a list of dictionaries by a specific value ---\nstudents = [\n    {\"name\": \"John\", \"age\": 20},\n    {\"name\": \"Jane\", \"age\": 22},\n    {\"name\": \"Doe\", \"age\": 19}\n]\nprint(\"\\nOriginal students data:\", students)\nsorted_students_by_age = sorted(students, key=lambda student: student[\"age\"])\nprint(\"Sorted students (by age):\", sorted_students_by_age)\n```\n\n**Key Points about `sorted()`:**\n*   **Returns a new list:** Always creates and returns a new list.\n*   **Works on any iterable:** Can sort lists, tuples, sets, strings (sorting characters), etc. The result is always a list.\n\n---\n\n## Which one to choose?\n\n*   Use `list.sort()`:\n    *   If you *don't need* the original unsorted list.\n    *   If you want to modify the list in-place for efficiency (less memory usage).\n*   Use `sorted()`:\n    *   If you *need to preserve* the original list.\n    *   If you want to sort an iterable that isn't a list (e.g., a tuple, set, dictionary items) and get a sorted list back.\n\nPython's built-in sort (Timsort) is highly optimized and efficient for most use cases, so you should almost always prefer these built-in methods over implementing your own sorting algorithms."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"Please give me python code to sort a list.\"\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTdQtZri1Brs"
      },
      "source": [
        "## Store your key in an environment variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZDX51Y27pN4"
      },
      "source": [
        "If you're using a different development environment (or calling the Gemini API through `cURL` in your terminal), it's recommended to store your key in an environment variable.\n",
        "\n",
        "To store your key in an environment variable, open your terminal and run:\n",
        "\n",
        "```export GOOGLE_API_KEY=\"YOUR_API_KEY\"```\n",
        "\n",
        "If you're using Python, you can add these two lines to your notebook to read the key:\n",
        "\n",
        "```\n",
        "import os\n",
        "client = genai.Client(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "```\n",
        "\n",
        "Alternatively, if it isn't provided explicitly, the client will look for the API key.\n",
        "\n",
        "```\n",
        "client = genai.Client()\n",
        "```\n",
        "\n",
        "Or, if you're calling the API through your terminal using `cURL`, you can copy and paste this code to read your key from the environment variable.\n",
        "\n",
        "```\n",
        "curl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n",
        "    -H 'Content-Type: application/json' \\\n",
        "    -X POST \\\n",
        "    -d '{\n",
        "      \"contents\": [{\n",
        "        \"parts\":[{\n",
        "          \"text\": \"Please give me Python code to sort a list.\"\n",
        "        }]\n",
        "      }]\n",
        "    }'\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAOKOcax1xZY"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "Now that you know how to manage your API key, you've everything to [get started](./Get_started.ipynb) with Gemini. Check all the [quickstart guides](https://github.com/google-gemini/cookbook/tree/main/quickstarts) from the Cookbook, and in particular the [Get started](./Get_started.ipynb) one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ae50dac"
      },
      "source": [
        "Let's explore using a Hugging Face model for Text-to-Speech (TTS). We'll use the `transformers` library to load a pre-trained TTS model and generate audio from text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "565ec5f2"
      },
      "source": [
        "!pip install transformers accelerate soundfile -q"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb2fe608",
        "outputId": "b37cbe2a-985a-4475-9e0e-94da7f565dac"
      },
      "source": [
        "from transformers import pipeline\n",
        "import soundfile as sf\n",
        "import IPython.display as ipd\n",
        "import torch # Import torch\n",
        "\n",
        "# Load a pre-trained TTS model from Hugging Face\n",
        "# We will try a different model that is known to work with the text-to-speech pipeline\n",
        "# Let's try suno/bark, which is known for realistic speech\n",
        "\n",
        "model_id = \"suno/bark\"\n",
        "\n",
        "try:\n",
        "    # suno/bark is generally compatible with the text-to-speech pipeline\n",
        "    tts_pipeline = pipeline(\"text-to-speech\", model=model_id)\n",
        "\n",
        "    # Text to synthesize\n",
        "    text = \"Hello, this is a test of the text-to-speech model from suno bark.\"\n",
        "\n",
        "    # Generate speech\n",
        "    # The pipeline should handle the model and processor loading internally for supported models\n",
        "    speech = tts_pipeline(text)\n",
        "\n",
        "    # The output is a dictionary with 'audio' (numpy array) and 'sampling_rate'\n",
        "    audio_array = speech['audio']\n",
        "    sampling_rate = speech['sampling_rate']\n",
        "\n",
        "    # Save the audio to a file (optional)\n",
        "    sf.write(\"output_speech_bark.wav\", audio_array, sampling_rate)\n",
        "\n",
        "    # Play the audio in the notebook\n",
        "    print(\"Playing generated speech:\")\n",
        "    display(ipd.Audio(audio_array, rate=sampling_rate))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"Please ensure you have the necessary dependencies installed (like soundfile and potentially scipy).\")\n",
        "    print(\"Also, check the model card on Hugging Face for suno/bark for any specific instructions.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: Error opening 'output_speech_bark.wav': Format not recognised.\n",
            "Please ensure you have the necessary dependencies installed (like soundfile and potentially scipy).\n",
            "Also, check the model card on Hugging Face for suno/bark for any specific instructions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-mUvFsJvz8O",
        "outputId": "70caea19-94fb-4ead-e78b-0c407626559a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dae4983"
      },
      "source": [
        "This code demonstrates how to use a Hugging Face TTS model to convert text into speech.\n",
        "\n",
        "Next, we can look into integrating image generation models and then consider how to serve these capabilities in a web environment, potentially using Hugging Face Spaces or a lightweight web framework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "85bed60d",
        "outputId": "55680386-7816-4800-d7f5-d15c3b39572a"
      },
      "source": [
        "# CFG coef goes here because the model was trained with CFG distillation,\n",
        "# so it's not _actually_ doing CFG at inference time.\n",
        "# Also, if you are generating a dialog, you should have two voices in the list.\n",
        "condition_attributes = tts_model.make_condition_attributes(\n",
        "    [voice_path], cfg_coef=2.0\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tts_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-2258430933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# so it's not _actually_ doing CFG at inference time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Also, if you are generating a dialog, you should have two voices in the list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m condition_attributes = tts_model.make_condition_attributes(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mvoice_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tts_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "1ecb7d23",
        "outputId": "0332a517-ec52-43ae-8c8e-d10ac8142464"
      },
      "source": [
        "print(\"Generating audio...\")\n",
        "\n",
        "pcms = []\n",
        "def _on_frame(frame):\n",
        "    print(\"Step\", len(pcms), end=\"\\r\")\n",
        "    if (frame != -1).all():\n",
        "        pcm = tts_model.mimi.decode(frame[:, 1:, :]).cpu().numpy()\n",
        "        pcms.append(np.clip(pcm[0, 0], -1, 1))\n",
        "\n",
        "# You could also generate multiple audios at once by extending the following lists.\n",
        "all_entries = [entries]\n",
        "all_condition_attributes = [condition_attributes]\n",
        "with tts_model.mimi.streaming(len(all_entries)):\n",
        "    result = tts_model.generate(all_entries, all_condition_attributes, on_frame=_on_frame)\n",
        "\n",
        "print(\"Done generating.\")\n",
        "audio = np.concatenate(pcms, axis=-1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating audio...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'entries' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-996011298.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# You could also generate multiple audios at once by extending the following lists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mall_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mall_condition_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcondition_attributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtts_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'entries' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "2f2d2630",
        "outputId": "85c8e5f2-d769-4cc5-fa8b-cf641e9aa2d1"
      },
      "source": [
        "display(\n",
        "    Audio(audio, rate=tts_model.mimi.sample_rate, autoplay=True)\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Audio' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-3860513425.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m display(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtts_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Audio' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Authentication.ipynb",
      "provenance": []
    },
    "google": {
      "image_path": "/site-assets/images/share.png",
      "keywords": [
        "examples",
        "googleai",
        "samplecode",
        "python",
        "embed",
        "function"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}